{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集成了水印、美学、CLIP模型，用于给图文质量打分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import timm\n",
    "from torchvision import transforms as T\n",
    "import open_clip\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from PIL import Image\n",
    "\n",
    "class AestheticsMLP(pl.LightningModule):\n",
    "    # 美学判别器是基于CLIP的基础上接了一个MLP\n",
    "    def __init__(self, input_size, xcol='emb', ycol='avg_rating'):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.xcol = xcol\n",
    "        self.ycol = ycol\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.input_size, 1024),\n",
    "            #nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 128),\n",
    "            #nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            #nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(64, 16),\n",
    "            #nn.ReLU(),\n",
    "\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "            x = batch[self.xcol]\n",
    "            y = batch[self.ycol].reshape(-1, 1)\n",
    "            x_hat = self.layers(x)\n",
    "            loss = F.mse_loss(x_hat, y)\n",
    "            return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch[self.xcol]\n",
    "        y = batch[self.ycol].reshape(-1, 1)\n",
    "        x_hat = self.layers(x)\n",
    "        loss = F.mse_loss(x_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "class WaterMarkModel(nn.Module):\n",
    "    def __init__(self, model_path='./watermark_model_v1.pt'):\n",
    "        super(WaterMarkModel, self).__init__()\n",
    "        # model definition\n",
    "        self.model = timm.create_model(\n",
    "                'efficientnet_b3a', pretrained=True, num_classes=2)\n",
    "\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            # 1536 is the orginal in_features\n",
    "            nn.Linear(in_features=1536, out_features=625),\n",
    "            nn.ReLU(),  # ReLu to be the activation function\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=625, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=2),\n",
    "        )\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterSystem:\n",
    "    def __init__(\n",
    "                    self, \n",
    "                    clip_model_path=\"IDEA-CCNL/Taiyi-CLIP-RoBERTa-102M-ViT-L-Chinese\",\n",
    "                    aesthetics_model_path=\"./ava+logos-l14-linearMSE.pth\",\n",
    "                    watermark_model_path=\"./watermark_model_v1.pt\"\n",
    "                ):\n",
    "        self.clip_model_path = clip_model_path\n",
    "        self.aesthetics_model_path = aesthetics_model_path\n",
    "        self.watermark_model_path = watermark_model_path\n",
    "\n",
    "    def init_clip_model(self, ):\n",
    "        # 此处初始化clip模型，返回模型、tokenizer、processor\n",
    "        text_encoder = BertModel.from_pretrained(self.clip_model_path).eval().cuda()\n",
    "        text_tokenizer = BertTokenizer.from_pretrained(self.clip_model_path)\n",
    "        clip_model, _, processor = open_clip.create_model_and_transforms('ViT-L-14', pretrained='openai')\n",
    "        clip_model = clip_model.eval().cuda()\n",
    "        self.text_encoder, self.text_tokenizer, self.clip_model, self.processor = text_encoder, text_tokenizer, clip_model, processor\n",
    "        print(\"clip model loaded\")\n",
    "        return None\n",
    "\n",
    "    def init_aesthetics_model(self, ):\n",
    "        # 此处初始化美学模型\n",
    "        self.aesthetics_model = AestheticsMLP(768)\n",
    "        self.aesthetics_model.load_state_dict(torch.load(self.aesthetics_model_path))\n",
    "        self.aesthetics_model.eval().cuda()\n",
    "        print(\"aesthetics model loaded\")\n",
    "        return None\n",
    "\n",
    "    def init_watermark_model(self, ):\n",
    "        self.watermark_model = WaterMarkModel(self.watermark_model_path)\n",
    "        self.watermark_model.eval().cuda()\n",
    "        self.watermark_processor =  T.Compose([\n",
    "                                                T.Resize((256, 256)),\n",
    "                                                T.ToTensor(),\n",
    "                                                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                            ])\n",
    "        print(\"watermark model loaded\")\n",
    "        return None\n",
    "\n",
    "    def get_image_feature(self, images):\n",
    "        # 此处返回图像的特征向量\n",
    "        if isinstance(images, list):\n",
    "            images = torch.stack([self.processor(image) for image in images]).cuda()\n",
    "        elif isinstance(images, torch.Tensor):\n",
    "            images = images.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = self.clip_model.encode_image(images)\n",
    "            image_features /= image_features.norm(dim=1, keepdim=True)\n",
    "        return image_features\n",
    "    \n",
    "    def get_text_feature(self, text):\n",
    "        # 此处返回文本的特征向量\n",
    "        if isinstance(text, list) or isinstance(text, str):\n",
    "            text = self.text_tokenizer(text, return_tensors='pt', padding=True)['input_ids'].cuda()\n",
    "        elif isinstance(text, torch.Tensor):\n",
    "            text = text.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            text_features = self.text_encoder(text)[1]\n",
    "            text_features /= text_features.norm(dim=1, keepdim=True)\n",
    "        return text_features\n",
    "\n",
    "    def calculate_clip_score(self, features1, features2):\n",
    "        # 此处2个特征向量的相似度，输入可以是 图片+文本、文本+文本、图片+图片。\n",
    "        # 返回的是相似度矩阵，维度为 f1.shape[0] * f2.shape[0]\n",
    "        score_matrix =  features1 @ features2.t()\n",
    "        return score_matrix\n",
    "\n",
    "    def get_aesthetics_score(self, features):\n",
    "        # 此处返回美学分数，传入的是CLIP的feature, 先计算get_image_feature在传入此函数~(模型是ViT-L-14)\n",
    "        with torch.no_grad():\n",
    "            scores = self.aesthetics_model(features)\n",
    "            scores = scores[:, 0].detach().cpu().numpy()\n",
    "        return scores\n",
    "    \n",
    "    def get_watermark_score(self, images):\n",
    "        if isinstance(images, list):\n",
    "            images = torch.stack([self.watermark_processor(image) for image in images]).cuda()\n",
    "        elif isinstance(images, torch.Tensor):\n",
    "            images = images.cuda()\n",
    "        with torch.no_grad():\n",
    "            pred = self.watermark_model(images)\n",
    "            watermark_scores = F.softmax(pred, dim=1)[:,0].detach().cpu().numpy()\n",
    "\n",
    "        return watermark_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小规模数据测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = FilterSystem()\n",
    "demo.init_clip_model()\n",
    "demo.init_aesthetics_model()\n",
    "demo.init_watermark_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './demo_images/watermark_example.png'\n",
    "image_path2 = './demo_images/mengna.jpg'\n",
    "image_path3 = './demo_images/shuiyin.jpg'\n",
    "image_path4 = './demo_images/1.jpg'\n",
    "image_demo =  [Image.open(image_path).convert('RGB'), Image.open(image_path2).convert('RGB'), Image.open(image_path3).convert('RGB'), Image.open(image_path4).convert('RGB')]\n",
    "image_feature = demo.get_image_feature(image_demo,)  # 计算图片特征，传入图片列表，一般而言，可以在数据库保存这个东西，用于响应文本query\n",
    "aes_score = demo.get_aesthetics_score(image_feature)  # 计算美学分数，传入图片特征，一般而言，可以在数据库保存这个东西，用于响应文本query\n",
    "print(aes_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_demo = ['一副很美的画','港口小船', '蒙娜丽莎'] # 这里也可以只有一个文本，也就是query\n",
    "text_feature = demo.get_text_feature(text_demo) # 计算文本特征，传入文本列表\n",
    "similarity = demo.calculate_clip_score(image_feature, text_feature)  # 计算相似度\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermark_score = demo.get_watermark_score(image_demo)\n",
    "print(watermark_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取处理保存（单个进程）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data setting\n",
    "root_path = \"./project/dataset/laion_chinese_cwf/image_part00\"\n",
    "all_folders = sorted(os.listdir(root_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setting\n",
    "filter_model = FilterSystem()\n",
    "filter_model.init_clip_model()\n",
    "filter_model.init_aesthetics_model()\n",
    "filter_model.init_watermark_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FilterSystem\n",
    "from dataset import TxtDataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def sub_process(filter_model, each_folder_path):\n",
    "    each_dataset = TxtDataset(each_folder_path)\n",
    "    each_dataloader = DataLoader(each_dataset, batch_size=8, shuffle=False, num_workers=8)\n",
    "\n",
    "    image_paths = []\n",
    "    aes_scores = []\n",
    "    clip_scores = []\n",
    "    watermark_scores = []\n",
    "    for iii, (batch_image_paths, texts,) in enumerate(tqdm(each_dataloader)):\n",
    "        images =  [Image.open(each_image_path).convert(\"RGB\") for each_image_path in batch_image_paths]\n",
    "        image_paths.extend(batch_image_paths)\n",
    "\n",
    "        image_features = filter_model.get_image_feature(images,)  # 计算图片特征，传入图片列表，一般而言，可以在数据库保存这个东西，用于响应文本query\n",
    "        aes_score = filter_model.get_aesthetics_score(image_features)  # 计算美学分数，传入图片特征，一般而言，可以在数据库保存这个东西，用于响应文本query\n",
    "        aes_scores.extend(aes_score)\n",
    "\n",
    "        text_features = filter_model.get_text_feature(list(texts)) # 计算文本特征，传入文本列表\n",
    "        clip_score = filter_model.calculate_clip_score(image_features, text_features)  # 计算相似度\n",
    "        clip_scores.extend(torch.diagonal(clip_score).detach().cpu().numpy())  # 需要取对角线，只需要自己和对应文本的相似度\n",
    "\n",
    "        watermark_score = filter_model.get_watermark_score(images)  # 计算水印分数，传入图片路径列表\n",
    "        watermark_scores.extend(watermark_score)\n",
    "        \n",
    "        # print('aes_score:', aes_score, '\\n',\n",
    "        #     'clip_score:', clip_score, '\\n',\n",
    "        #     'watermark_score:', watermark_score, '\\n',\n",
    "        #     'image_paths:', image_paths, '\\n',\n",
    "        #     'texts:', texts)\n",
    "        \n",
    "    score_pd = pd.DataFrame({'image_path': image_paths, 'aes_score': aes_scores, 'clip_score': clip_scores, 'watermark_score': watermark_scores})\n",
    "    score_pd.to_csv(os.path.join(each_folder_path, 'score.csv'), index=False)\n",
    "    print('save score.csv in {}'.format(each_folder_path), '\\n', '-'*20)\n",
    "\n",
    "for each_folder in all_folders[:10]:\n",
    "    each_folder_path = os.path.join(root_path, each_folder)\n",
    "    sub_process(filter_model, each_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FilterSystem\n",
    "from dataset import TxtDataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor, wait, ALL_COMPLETED\n",
    "\n",
    "p = ProcessPoolExecutor(max_workers=4)\n",
    "\n",
    "def sub_process(filter_model, each_folder_path):\n",
    "    each_dataset = TxtDataset(each_folder_path)\n",
    "    each_dataloader = DataLoader(each_dataset, batch_size=8, shuffle=False, num_workers=8)\n",
    "\n",
    "    image_paths = []\n",
    "    aes_scores = []\n",
    "    clip_scores = []\n",
    "    watermark_scores = []\n",
    "    for iii, (batch_image_paths, texts,) in enumerate(each_dataloader):\n",
    "        images =  [Image.open(each_image_path) for each_image_path in batch_image_paths]\n",
    "        image_paths.extend(batch_image_paths)\n",
    "\n",
    "        image_features = filter_model.get_image_feature(images,)  # 计算图片特征，传入图片列表，一般而言，可以在数据库保存这个东西，用于响应文本query\n",
    "        aes_score = filter_model.get_aesthetics_score(image_features)  # 计算美学分数，传入图片特征，一般而言，可以在数据库保存这个东西，用于响应文本query\n",
    "        aes_scores.extend(aes_score)\n",
    "\n",
    "        text_features = filter_model.get_text_feature(list(texts)) # 计算文本特征，传入文本列表\n",
    "        clip_score = filter_model.calculate_clip_score(image_features, text_features)  # 计算相似度\n",
    "        clip_scores.extend(torch.diagonal(clip_score).detach().cpu().numpy())  # 需要取对角线，只需要自己和对应文本的相似度\n",
    "\n",
    "        watermark_score = filter_model.get_watermark_score(images)  # 计算水印分数，传入图片路径列表\n",
    "        watermark_scores.extend(watermark_score)\n",
    "        \n",
    "        # print('aes_score:', aes_score, '\\n',\n",
    "        #     'clip_score:', clip_score, '\\n',\n",
    "        #     'watermark_score:', watermark_score, '\\n',\n",
    "        #     'image_paths:', image_paths, '\\n',\n",
    "        #     'texts:', texts)\n",
    "        \n",
    "    score_pd = pd.DataFrame({'image_path': image_paths, 'aes_score': aes_scores, 'clip_score': clip_scores, 'watermark_score': watermark_scores})\n",
    "    score_pd.to_csv(os.path.join(each_folder_path, 'score.csv'), index=False)\n",
    "    print('save score.csv in {}'.format(each_folder_path), '\\n', '-'*20)\n",
    "\n",
    "for each_folder in all_folders[:10]:\n",
    "    each_folder_path = os.path.join(root_path, each_folder)\n",
    "    f1 = p.submit(sub_process, model_pool[0], each_folder_path)\n",
    "    f2 = p.submit(sub_process, model_pool[1], each_folder_path)\n",
    "    f3 = p.submit(sub_process, model_pool[2], each_folder_path)\n",
    "    f4 = p.submit(sub_process, model_pool[3], each_folder_path)\n",
    "    res = wait([f1, f2, f3, f4], return_when=ALL_COMPLETED)\n",
    "p.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用model pool来开启4进程跑\n",
    "model_pool = [FilterSystem() for i in range(4)]\n",
    "for model in model_pool:\n",
    "    model.init_clip_model()\n",
    "    model.init_aesthetics_model()\n",
    "    model.init_watermark_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aes_scores, clip_scores, watermark_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('image_paths:', image_paths, '\\n',  'texts:', texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch lightning + multi process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class ScoreSystem(pl.LightningModule):\n",
    "    def __init__(Self):\n",
    "        super().__init__()\n",
    "        self.text_encoder, self.text_tokenizer, self.clip_model, self.processor = self.init_clip_model()\n",
    "        self.aesthetics_model = self.init_aesthetics_model()\n",
    "        self.watermark_model, self.watermark_processor = self.init_watermark_model()\n",
    "\n",
    "    def init_clip_model(self):\n",
    "        text_encoder = BertModel.from_pretrained(self.clip_model_path).eval().cuda()\n",
    "        text_tokenizer = BertTokenizer.from_pretrained(self.clip_model_path)\n",
    "        clip_model, _, processor = open_clip.create_model_and_transforms('ViT-L-14', pretrained='openai')\n",
    "        clip_model = clip_model.eval().cuda()\n",
    "        print(\"clip model loaded\")\n",
    "        return text_encoder, text_tokenizer, clip_model, processor\n",
    "\n",
    "    def init_aesthetics_model(self, ):\n",
    "        # 此处初始化美学模型\n",
    "        aesthetics_model = AestheticsMLP(768)\n",
    "        aesthetics_model.load_state_dict(torch.load(self.aesthetics_model_path)).eval().cuda()\n",
    "        print(\"aesthetics model loaded\")\n",
    "        return aesthetics_model\n",
    "\n",
    "    def init_watermark_model(self, ):\n",
    "        watermark_model = WaterMarkModel(self.watermark_model_path)\n",
    "        watermark_model.eval().cuda()\n",
    "        watermark_processor =  T.Compose([\n",
    "                                                T.Resize((256, 256)),\n",
    "                                                T.ToTensor(),\n",
    "                                                T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                            ])\n",
    "        print(\"watermark model loaded\")\n",
    "        return watermark_model, watermark_processor\n",
    "\n",
    "    def get_image_feature(self, images):\n",
    "        # 此处返回图像的特征向量\n",
    "        if isinstance(images, list):\n",
    "            images = torch.stack([self.processor(image) for image in images]).cuda()\n",
    "        elif isinstance(images, torch.Tensor):\n",
    "            images = images.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = self.clip_model.encode_image(images)\n",
    "            image_features /= image_features.norm(dim=1, keepdim=True)\n",
    "        return image_features\n",
    "    \n",
    "    def get_text_feature(self, text):\n",
    "        # 此处返回文本的特征向量\n",
    "        if isinstance(text, list) or isinstance(text, str):\n",
    "            text = self.text_tokenizer(text, return_tensors='pt', padding=True)['input_ids'].cuda()\n",
    "        elif isinstance(text, torch.Tensor):\n",
    "            text = text.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            text_features = self.text_encoder(text)[1]\n",
    "            text_features /= text_features.norm(dim=1, keepdim=True)\n",
    "        return text_features\n",
    "\n",
    "    def calculate_clip_score(self, features1, features2):\n",
    "        # 此处2个特征向量的相似度，输入可以是 图片+文本、文本+文本、图片+图片。\n",
    "        # 返回的是相似度矩阵，维度为 f1.shape[0] * f2.shape[0]\n",
    "        score_matrix =  features1 @ features2.t()\n",
    "        return score_matrix\n",
    "\n",
    "    def get_aesthetics_score(self, features):\n",
    "        # 此处返回美学分数，传入的是CLIP的feature, 先计算get_image_feature在传入此函数~(模型是ViT-L-14)\n",
    "        with torch.no_grad():\n",
    "            scores = self.aesthetics_model(features)\n",
    "            scores = scores[:, 0].detach().cpu().numpy()\n",
    "        return scores\n",
    "    \n",
    "    def get_watermark_score(self, images):\n",
    "        if isinstance(images, list):\n",
    "            images = torch.stack([self.watermark_processor(image) for image in images]).cuda()\n",
    "        elif isinstance(images, torch.Tensor):\n",
    "            images = images.cuda()\n",
    "        with torch.no_grad():\n",
    "            pred = self.watermark_model(images)\n",
    "            watermark_scores = F.softmax(pred, dim=1)[:,0].detach().cpu().numpy()\n",
    "\n",
    "        return watermark_scores\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        images, texts = batch   \n",
    "        # TODO 这里要么传入处理后的2种图片，要么传入纯图片，然后在下面的函数处理。（目前是传入纯图片）\n",
    "        image_features = self.get_image_feature(images)\n",
    "        text_features = self.get_text_feature(texts)\n",
    "        clip_scores = self.calculate_clip_score(image_features, text_features)\n",
    "        aes_scores = self.get_aesthetics_score(image_features)\n",
    "        watermark_scores = self.get_watermark_score(images)\n",
    "        return clip_scores, aes_scores, watermark_scores\n",
    "\n",
    "    def on_predict_epoch_end(self, outputs):\n",
    "        # 此处返回所有预测结果\n",
    "        clip_scores = torch.cat([output[0] for output in outputs], dim=0)\n",
    "        aes_scores = torch.cat([output[1] for output in outputs], dim=0)\n",
    "        watermark_scores = torch.cat([output[2] for output in outputs], dim=0)\n",
    "        return clip_scores, aes_scores, watermark_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cc247672a8bfe61dc951074f9ca89ab002dc0f7e14586a8bb0828228bebeefa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
